import streamlit as st
from audio_recorder_streamlit import audio_recorder
from datetime import datetime
from pathlib import Path
import os

from faster_whisper import WhisperModel
import time
import numpy as np

import base64
import requests
import pprint
import json

import google.generativeai as genai

model_size = "large-v3"  # ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã‚’æŒ‡å®š
model = WhisperModel(model_size, device="cuda", compute_type="float16")  # ã“ã“ã§ã¯ä¾‹ã¨ã—ã¦FP16ã‚’ä½¿ç”¨

GOOGLE_API_KEY= "AIzaSyCbRltHDKdUCZZ3p7rNkFoifmlT6aIdouM"
genai.configure(api_key=GOOGLE_API_KEY)
model_genai = genai.GenerativeModel('gemini-pro')

def save_audio_with_date(audio_bytes, folder_path="streamlit/saved_audios"):
    # ç¾åœ¨ã®æ—¥æ™‚ã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    date_str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    file_name = f"audio_{date_str}.wav"
    
    # æŒ‡å®šã—ãŸãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’Pathã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
    folder_path = Path(folder_path)
    
    # ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã«ä½œæˆ
    if not folder_path.exists():
        os.makedirs(folder_path)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ
    full_path = folder_path / file_name
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    with open(full_path, "wb") as file:
        file.write(audio_bytes)

    # è¨ˆæ¸¬é–‹å§‹æ™‚åˆ»
    start_time = time.time()


    with st.chat_message("user", avatar="ğŸ¦–"):
        st.write(f"full_path: {full_path}")
        # éŒ²éŸ³ã—ãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãèµ·ã“ã—
        segments, info = model.transcribe(str(full_path), beam_size=5)

        # è¨ˆæ¸¬çµ‚äº†æ™‚åˆ»ã¨å®Ÿè¡Œæ™‚é–“ã®è¨ˆç®—ã€å‡ºåŠ›
        end_time = time.time()
        elapsed_time = end_time - start_time
        st.write(f"æ–‡å­—ãŠè¶Šã—æ™‚é–“: {elapsed_time}ç§’")

        # æ¤œå‡ºã•ã‚ŒãŸè¨€èªã¨ãã®ç¢ºç‡ã€æ›¸ãèµ·ã“ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
        st.write("Detected language '%s' with probability %f" % (info.language, info.language_probability))
        for segment in segments:
            st.write("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))


    with st.chat_message("assistant", avatar="ğŸ¤–"):
        start_time = time.time()
        response = model_genai.generate_content(f"{segment.text}")
        st.write(response.text)
        # è¨ˆæ¸¬çµ‚äº†æ™‚åˆ»ã¨å®Ÿè¡Œæ™‚é–“ã®è¨ˆç®—ã€å‡ºåŠ›
        end_time = time.time()
        elapsed_time = end_time - start_time
        st.write(f"å›ç­”æ™‚é–“: {elapsed_time}ç§’")


    return full_path  # ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¿”ã™

# Example usage with Streamlit:
def main():
    st.title("Voice to Text Transcription 2")
    
    # Record audio using Streamlit widget
    audio_bytes = audio_recorder(pause_threshold=30)
    
    # éŸ³å£°ã‚’æŒ‡å®šã®ãƒ•ã‚©ãƒ«ãƒ€ã«æ—¥ä»˜æƒ…å ±ã‚’ä»˜ä¸ã—ã¦ä¿å­˜
    if audio_bytes:
        saved_file_path = save_audio_with_date(audio_bytes, "streamlit/saved_audios")
        st.write(f"Audio saved to: {saved_file_path}")

if __name__ == "__main__":
    main()
